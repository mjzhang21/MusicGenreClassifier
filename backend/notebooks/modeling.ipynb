{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ac68f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb5e3c4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>length</th>\n",
       "      <th>chroma_stft_mean</th>\n",
       "      <th>chroma_stft_var</th>\n",
       "      <th>rms_mean</th>\n",
       "      <th>rms_var</th>\n",
       "      <th>spectral_centroid_mean</th>\n",
       "      <th>spectral_centroid_var</th>\n",
       "      <th>spectral_bandwidth_mean</th>\n",
       "      <th>spectral_bandwidth_var</th>\n",
       "      <th>...</th>\n",
       "      <th>mfcc16_var</th>\n",
       "      <th>mfcc17_mean</th>\n",
       "      <th>mfcc17_var</th>\n",
       "      <th>mfcc18_mean</th>\n",
       "      <th>mfcc18_var</th>\n",
       "      <th>mfcc19_mean</th>\n",
       "      <th>mfcc19_var</th>\n",
       "      <th>mfcc20_mean</th>\n",
       "      <th>mfcc20_var</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blues.00000.wav</td>\n",
       "      <td>661794</td>\n",
       "      <td>0.350088</td>\n",
       "      <td>0.088757</td>\n",
       "      <td>0.130228</td>\n",
       "      <td>0.002827</td>\n",
       "      <td>1784.165850</td>\n",
       "      <td>129774.064525</td>\n",
       "      <td>2002.449060</td>\n",
       "      <td>85882.761315</td>\n",
       "      <td>...</td>\n",
       "      <td>52.420910</td>\n",
       "      <td>-1.690215</td>\n",
       "      <td>36.524071</td>\n",
       "      <td>-0.408979</td>\n",
       "      <td>41.597103</td>\n",
       "      <td>-2.303523</td>\n",
       "      <td>55.062923</td>\n",
       "      <td>1.221291</td>\n",
       "      <td>46.936035</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blues.00001.wav</td>\n",
       "      <td>661794</td>\n",
       "      <td>0.340914</td>\n",
       "      <td>0.094980</td>\n",
       "      <td>0.095948</td>\n",
       "      <td>0.002373</td>\n",
       "      <td>1530.176679</td>\n",
       "      <td>375850.073649</td>\n",
       "      <td>2039.036516</td>\n",
       "      <td>213843.755497</td>\n",
       "      <td>...</td>\n",
       "      <td>55.356403</td>\n",
       "      <td>-0.731125</td>\n",
       "      <td>60.314529</td>\n",
       "      <td>0.295073</td>\n",
       "      <td>48.120598</td>\n",
       "      <td>-0.283518</td>\n",
       "      <td>51.106190</td>\n",
       "      <td>0.531217</td>\n",
       "      <td>45.786282</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blues.00002.wav</td>\n",
       "      <td>661794</td>\n",
       "      <td>0.363637</td>\n",
       "      <td>0.085275</td>\n",
       "      <td>0.175570</td>\n",
       "      <td>0.002746</td>\n",
       "      <td>1552.811865</td>\n",
       "      <td>156467.643368</td>\n",
       "      <td>1747.702312</td>\n",
       "      <td>76254.192257</td>\n",
       "      <td>...</td>\n",
       "      <td>40.598766</td>\n",
       "      <td>-7.729093</td>\n",
       "      <td>47.639427</td>\n",
       "      <td>-1.816407</td>\n",
       "      <td>52.382141</td>\n",
       "      <td>-3.439720</td>\n",
       "      <td>46.639660</td>\n",
       "      <td>-2.231258</td>\n",
       "      <td>30.573025</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>blues.00003.wav</td>\n",
       "      <td>661794</td>\n",
       "      <td>0.404785</td>\n",
       "      <td>0.093999</td>\n",
       "      <td>0.141093</td>\n",
       "      <td>0.006346</td>\n",
       "      <td>1070.106615</td>\n",
       "      <td>184355.942417</td>\n",
       "      <td>1596.412872</td>\n",
       "      <td>166441.494769</td>\n",
       "      <td>...</td>\n",
       "      <td>44.427753</td>\n",
       "      <td>-3.319597</td>\n",
       "      <td>50.206673</td>\n",
       "      <td>0.636965</td>\n",
       "      <td>37.319130</td>\n",
       "      <td>-0.619121</td>\n",
       "      <td>37.259739</td>\n",
       "      <td>-3.407448</td>\n",
       "      <td>31.949339</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blues.00004.wav</td>\n",
       "      <td>661794</td>\n",
       "      <td>0.308526</td>\n",
       "      <td>0.087841</td>\n",
       "      <td>0.091529</td>\n",
       "      <td>0.002303</td>\n",
       "      <td>1835.004266</td>\n",
       "      <td>343399.939274</td>\n",
       "      <td>1748.172116</td>\n",
       "      <td>88445.209036</td>\n",
       "      <td>...</td>\n",
       "      <td>86.099236</td>\n",
       "      <td>-5.454034</td>\n",
       "      <td>75.269707</td>\n",
       "      <td>-0.916874</td>\n",
       "      <td>53.613918</td>\n",
       "      <td>-4.404827</td>\n",
       "      <td>62.910812</td>\n",
       "      <td>-11.703234</td>\n",
       "      <td>55.195160</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          filename  length  chroma_stft_mean  chroma_stft_var  rms_mean  \\\n",
       "0  blues.00000.wav  661794          0.350088         0.088757  0.130228   \n",
       "1  blues.00001.wav  661794          0.340914         0.094980  0.095948   \n",
       "2  blues.00002.wav  661794          0.363637         0.085275  0.175570   \n",
       "3  blues.00003.wav  661794          0.404785         0.093999  0.141093   \n",
       "4  blues.00004.wav  661794          0.308526         0.087841  0.091529   \n",
       "\n",
       "    rms_var  spectral_centroid_mean  spectral_centroid_var  \\\n",
       "0  0.002827             1784.165850          129774.064525   \n",
       "1  0.002373             1530.176679          375850.073649   \n",
       "2  0.002746             1552.811865          156467.643368   \n",
       "3  0.006346             1070.106615          184355.942417   \n",
       "4  0.002303             1835.004266          343399.939274   \n",
       "\n",
       "   spectral_bandwidth_mean  spectral_bandwidth_var  ...  mfcc16_var  \\\n",
       "0              2002.449060            85882.761315  ...   52.420910   \n",
       "1              2039.036516           213843.755497  ...   55.356403   \n",
       "2              1747.702312            76254.192257  ...   40.598766   \n",
       "3              1596.412872           166441.494769  ...   44.427753   \n",
       "4              1748.172116            88445.209036  ...   86.099236   \n",
       "\n",
       "   mfcc17_mean  mfcc17_var  mfcc18_mean  mfcc18_var  mfcc19_mean  mfcc19_var  \\\n",
       "0    -1.690215   36.524071    -0.408979   41.597103    -2.303523   55.062923   \n",
       "1    -0.731125   60.314529     0.295073   48.120598    -0.283518   51.106190   \n",
       "2    -7.729093   47.639427    -1.816407   52.382141    -3.439720   46.639660   \n",
       "3    -3.319597   50.206673     0.636965   37.319130    -0.619121   37.259739   \n",
       "4    -5.454034   75.269707    -0.916874   53.613918    -4.404827   62.910812   \n",
       "\n",
       "   mfcc20_mean  mfcc20_var  label  \n",
       "0     1.221291   46.936035  blues  \n",
       "1     0.531217   45.786282  blues  \n",
       "2    -2.231258   30.573025  blues  \n",
       "3    -3.407448   31.949339  blues  \n",
       "4   -11.703234   55.195160  blues  \n",
       "\n",
       "[5 rows x 60 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/features_30_sec.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e11c37da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 60 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   filename                 1000 non-null   object \n",
      " 1   length                   1000 non-null   int64  \n",
      " 2   chroma_stft_mean         1000 non-null   float64\n",
      " 3   chroma_stft_var          1000 non-null   float64\n",
      " 4   rms_mean                 1000 non-null   float64\n",
      " 5   rms_var                  1000 non-null   float64\n",
      " 6   spectral_centroid_mean   1000 non-null   float64\n",
      " 7   spectral_centroid_var    1000 non-null   float64\n",
      " 8   spectral_bandwidth_mean  1000 non-null   float64\n",
      " 9   spectral_bandwidth_var   1000 non-null   float64\n",
      " 10  rolloff_mean             1000 non-null   float64\n",
      " 11  rolloff_var              1000 non-null   float64\n",
      " 12  zero_crossing_rate_mean  1000 non-null   float64\n",
      " 13  zero_crossing_rate_var   1000 non-null   float64\n",
      " 14  harmony_mean             1000 non-null   float64\n",
      " 15  harmony_var              1000 non-null   float64\n",
      " 16  perceptr_mean            1000 non-null   float64\n",
      " 17  perceptr_var             1000 non-null   float64\n",
      " 18  tempo                    1000 non-null   float64\n",
      " 19  mfcc1_mean               1000 non-null   float64\n",
      " 20  mfcc1_var                1000 non-null   float64\n",
      " 21  mfcc2_mean               1000 non-null   float64\n",
      " 22  mfcc2_var                1000 non-null   float64\n",
      " 23  mfcc3_mean               1000 non-null   float64\n",
      " 24  mfcc3_var                1000 non-null   float64\n",
      " 25  mfcc4_mean               1000 non-null   float64\n",
      " 26  mfcc4_var                1000 non-null   float64\n",
      " 27  mfcc5_mean               1000 non-null   float64\n",
      " 28  mfcc5_var                1000 non-null   float64\n",
      " 29  mfcc6_mean               1000 non-null   float64\n",
      " 30  mfcc6_var                1000 non-null   float64\n",
      " 31  mfcc7_mean               1000 non-null   float64\n",
      " 32  mfcc7_var                1000 non-null   float64\n",
      " 33  mfcc8_mean               1000 non-null   float64\n",
      " 34  mfcc8_var                1000 non-null   float64\n",
      " 35  mfcc9_mean               1000 non-null   float64\n",
      " 36  mfcc9_var                1000 non-null   float64\n",
      " 37  mfcc10_mean              1000 non-null   float64\n",
      " 38  mfcc10_var               1000 non-null   float64\n",
      " 39  mfcc11_mean              1000 non-null   float64\n",
      " 40  mfcc11_var               1000 non-null   float64\n",
      " 41  mfcc12_mean              1000 non-null   float64\n",
      " 42  mfcc12_var               1000 non-null   float64\n",
      " 43  mfcc13_mean              1000 non-null   float64\n",
      " 44  mfcc13_var               1000 non-null   float64\n",
      " 45  mfcc14_mean              1000 non-null   float64\n",
      " 46  mfcc14_var               1000 non-null   float64\n",
      " 47  mfcc15_mean              1000 non-null   float64\n",
      " 48  mfcc15_var               1000 non-null   float64\n",
      " 49  mfcc16_mean              1000 non-null   float64\n",
      " 50  mfcc16_var               1000 non-null   float64\n",
      " 51  mfcc17_mean              1000 non-null   float64\n",
      " 52  mfcc17_var               1000 non-null   float64\n",
      " 53  mfcc18_mean              1000 non-null   float64\n",
      " 54  mfcc18_var               1000 non-null   float64\n",
      " 55  mfcc19_mean              1000 non-null   float64\n",
      " 56  mfcc19_var               1000 non-null   float64\n",
      " 57  mfcc20_mean              1000 non-null   float64\n",
      " 58  mfcc20_var               1000 non-null   float64\n",
      " 59  label                    1000 non-null   object \n",
      "dtypes: float64(57), int64(1), object(2)\n",
      "memory usage: 468.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b15c6dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 57)\n",
      "(200, 57)\n",
      "(800,)\n",
      "(200,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GroupShuffleSplit, train_test_split\n",
    "\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_enc = le.fit_transform(df[\"label\"])  # Converts strings to integers\n",
    "\n",
    "# Features\n",
    "X = df.drop(columns=[\"label\", \"filename\", \"length\"]).values.astype(np.float64)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_enc, test_size=0.2, random_state=0\n",
    ")\n",
    "# gss = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=0)\n",
    "# train_idx, test_idx = next(gss.split(X, y_enc, groups=file_id))\n",
    "# X_train, X_test = X[train_idx], X[test_idx]\n",
    "# y_train, y_test = y_enc[train_idx], y_enc[test_idx]\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5bb0aaaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Train F1-macro</th>\n",
       "      <th>Test F1-macro</th>\n",
       "      <th>Fit Time (s)</th>\n",
       "      <th>Accuracy Gap</th>\n",
       "      <th>F1-macro Gap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.946875</td>\n",
       "      <td>0.72500</td>\n",
       "      <td>0.946076</td>\n",
       "      <td>0.716842</td>\n",
       "      <td>0.550435</td>\n",
       "      <td>0.221875</td>\n",
       "      <td>0.229235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.885000</td>\n",
       "      <td>0.72625</td>\n",
       "      <td>0.882864</td>\n",
       "      <td>0.716777</td>\n",
       "      <td>0.039715</td>\n",
       "      <td>0.158750</td>\n",
       "      <td>0.166087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.913125</td>\n",
       "      <td>0.70250</td>\n",
       "      <td>0.911040</td>\n",
       "      <td>0.692620</td>\n",
       "      <td>0.084124</td>\n",
       "      <td>0.210625</td>\n",
       "      <td>0.218420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.800938</td>\n",
       "      <td>0.68625</td>\n",
       "      <td>0.798946</td>\n",
       "      <td>0.681313</td>\n",
       "      <td>0.002925</td>\n",
       "      <td>0.114688</td>\n",
       "      <td>0.117632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.958125</td>\n",
       "      <td>0.67875</td>\n",
       "      <td>0.957063</td>\n",
       "      <td>0.672371</td>\n",
       "      <td>3.765162</td>\n",
       "      <td>0.279375</td>\n",
       "      <td>0.284692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.883125</td>\n",
       "      <td>0.65375</td>\n",
       "      <td>0.881054</td>\n",
       "      <td>0.640691</td>\n",
       "      <td>0.525871</td>\n",
       "      <td>0.229375</td>\n",
       "      <td>0.240363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HistGradientBoostingClassifier</td>\n",
       "      <td>0.936562</td>\n",
       "      <td>0.64750</td>\n",
       "      <td>0.934949</td>\n",
       "      <td>0.639904</td>\n",
       "      <td>2.681405</td>\n",
       "      <td>0.289062</td>\n",
       "      <td>0.295045</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Model  Train Accuracy  Test Accuracy  \\\n",
       "0                   MLPClassifier        0.946875        0.72500   \n",
       "1                             SVC        0.885000        0.72625   \n",
       "2              LogisticRegression        0.913125        0.70250   \n",
       "3            KNeighborsClassifier        0.800938        0.68625   \n",
       "4                   XGBClassifier        0.958125        0.67875   \n",
       "5          RandomForestClassifier        0.883125        0.65375   \n",
       "6  HistGradientBoostingClassifier        0.936562        0.64750   \n",
       "\n",
       "   Train F1-macro  Test F1-macro  Fit Time (s)  Accuracy Gap  F1-macro Gap  \n",
       "0        0.946076       0.716842      0.550435      0.221875      0.229235  \n",
       "1        0.882864       0.716777      0.039715      0.158750      0.166087  \n",
       "2        0.911040       0.692620      0.084124      0.210625      0.218420  \n",
       "3        0.798946       0.681313      0.002925      0.114688      0.117632  \n",
       "4        0.957063       0.672371      3.765162      0.279375      0.284692  \n",
       "5        0.881054       0.640691      0.525871      0.229375      0.240363  \n",
       "6        0.934949       0.639904      2.681405      0.289062      0.295045  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.calibration import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Classifiers\n",
    "classifiers = [\n",
    "    LogisticRegression(random_state=0),\n",
    "    SVC(random_state=0),\n",
    "    RandomForestClassifier(random_state=0, max_depth=6, min_samples_leaf=5),\n",
    "    HistGradientBoostingClassifier(\n",
    "        max_depth=3,  # shallower trees\n",
    "        min_samples_leaf=6,\n",
    "        learning_rate=0.01,  # slower learning rate\n",
    "        random_state=0,\n",
    "        l2_regularization=0.1,\n",
    "    ),\n",
    "    KNeighborsClassifier(),\n",
    "    MLPClassifier(random_state=0, max_iter=100),\n",
    "    XGBClassifier(\n",
    "        max_depth=4,  # shallower trees\n",
    "        learning_rate=0.008,  # smaller step size\n",
    "        random_state=0,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        reg_alpha=0.01,\n",
    "        reg_lambda=1.0,\n",
    "    ),\n",
    "]\n",
    "\n",
    "results = []\n",
    "\n",
    "for clf in classifiers:\n",
    "\n",
    "    # Add scaling where necessary\n",
    "    if isinstance(clf, (SVC, MLPClassifier, KNeighborsClassifier, LogisticRegression)):\n",
    "        pipeline = Pipeline([(\"scaler\", StandardScaler()), (\"clf\", clf)])\n",
    "    else:\n",
    "        pipeline = Pipeline([(\"clf\", clf)])\n",
    "\n",
    "    # Cross-validate\n",
    "    scores = cross_validate(\n",
    "        pipeline,\n",
    "        X_train,\n",
    "        y_train,\n",
    "        scoring={\n",
    "            \"accuracy\": \"accuracy\",\n",
    "            \"f1_macro\": \"f1_macro\",\n",
    "        },\n",
    "        return_train_score=True,\n",
    "    )\n",
    "\n",
    "    # Save mean scores only\n",
    "    results.append(\n",
    "        {\n",
    "            \"Model\": clf.__class__.__name__,\n",
    "            \"Train Accuracy\": np.mean(scores[\"train_accuracy\"]),\n",
    "            \"Test Accuracy\": np.mean(scores[\"test_accuracy\"]),\n",
    "            \"Train F1-macro\": np.mean(scores[\"train_f1_macro\"]),\n",
    "            \"Test F1-macro\": np.mean(scores[\"test_f1_macro\"]),\n",
    "            \"Fit Time (s)\": np.mean(scores[\"fit_time\"]),\n",
    "            \"Accuracy Gap\": np.mean(scores[\"train_accuracy\"])\n",
    "            - np.mean(scores[\"test_accuracy\"]),\n",
    "            \"F1-macro Gap\": np.mean(scores[\"train_f1_macro\"])\n",
    "            - np.mean(scores[\"test_f1_macro\"]),\n",
    "        }\n",
    "    )\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_results = pd.DataFrame(results)\n",
    "df_results = df_results.sort_values(\n",
    "    by=[\"Test F1-macro\", \"Test Accuracy\", \"F1-macro Gap\"],\n",
    "    ascending=[False, False, True],\n",
    ").reset_index(drop=True)\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2661f57b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Best SVC Params: {'clf__tol': 0.001, 'clf__kernel': 'rbf', 'clf__gamma': 0.01, 'clf__C': 2}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, StratifiedKFold\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipe = Pipeline([(\"scaler\", StandardScaler()), (\"clf\", SVC(random_state=0))])\n",
    "# Hyperparameter grid\n",
    "param_grid = {\n",
    "    \"clf__C\": [2],  # Regularization strength\n",
    "    \"clf__kernel\": [\"rbf\"],  # Common kernels\n",
    "    \"clf__gamma\": [0.01],  # For 'rbf' and 'poly'\n",
    "    \"clf__tol\": [1e-3],  # Convergence tolerance\n",
    "}\n",
    "scoring = {\"f1_macro\": \"f1_macro\", \"accuracy\": \"accuracy\"}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "random_search = RandomizedSearchCV(\n",
    "    pipe,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=30,  # number of random trials\n",
    "    scoring=scoring,\n",
    "    refit=\"f1_macro\",\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    return_train_score=True,\n",
    ")\n",
    "\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best SVC Params:\", random_search.best_params_)\n",
    "best_params = random_search.best_params_\n",
    "\n",
    "best_index = random_search.best_index_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "818a6a44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Train Accuracy (mean): 0.8956\n",
      "CV Test Accuracy (mean): 0.7238\n",
      "CV Train F1 (mean): 0.8937\n",
      "CV Test F1 (mean): 0.7155\n",
      "CV Fit Time (mean, s): 0.0743\n",
      "Holdout Accuracy: 0.6600\n",
      "Holdout F1 Score (macro): 0.6728\n",
      "Holdout Prediction Time (s): 0.0442\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    ")\n",
    "import time\n",
    "\n",
    "\n",
    "best_params = random_search.best_params_\n",
    "best_index = random_search.best_index_\n",
    "# CV summary from GridSearchCV\n",
    "best_train_acc = random_search.cv_results_[\"mean_train_accuracy\"][best_index]\n",
    "best_test_acc = random_search.cv_results_[\"mean_test_accuracy\"][best_index]\n",
    "best_train_f1 = random_search.cv_results_[\"mean_train_f1_macro\"][best_index]\n",
    "best_test_f1 = random_search.cv_results_[\"mean_test_f1_macro\"][best_index]\n",
    "fit_time = random_search.cv_results_[\"mean_fit_time\"][best_index]\n",
    "\n",
    "print(f\"CV Train Accuracy (mean): {best_train_acc:.4f}\")\n",
    "print(f\"CV Test Accuracy (mean): {best_test_acc:.4f}\")\n",
    "print(f\"CV Train F1 (mean): {best_train_f1:.4f}\")\n",
    "print(f\"CV Test F1 (mean): {best_test_f1:.4f}\")\n",
    "print(f\"CV Fit Time (mean, s): {fit_time:.4f}\")\n",
    "\n",
    "# Use the best estimator from GridSearchCV\n",
    "best_model = random_search.best_estimator_\n",
    "\n",
    "# Evaluate on hold-out test set\n",
    "start = time.time()\n",
    "y_pred_test = best_model.predict(X_test)\n",
    "test_time = time.time() - start\n",
    "\n",
    "# Compute metrics\n",
    "test_acc = accuracy_score(y_test, y_pred_test)\n",
    "test_f1 = f1_score(y_test, y_pred_test, average=\"macro\")\n",
    "\n",
    "# Print results\n",
    "print(f\"Holdout Accuracy: {test_acc:.4f}\")\n",
    "print(f\"Holdout F1 Score (macro): {test_f1:.4f}\")\n",
    "print(f\"Holdout Prediction Time (s): {test_time:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2e6535e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "Best Logistic Regression Params: {'clf__solver': 'saga', 'clf__penalty': 'l2', 'clf__class_weight': None, 'clf__C': 0.2}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Pipeline with Logistic Regression\n",
    "pipe = Pipeline(\n",
    "    [\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"clf\", LogisticRegression(random_state=0, max_iter=500)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Hyperparameter grid for Logistic Regression\n",
    "param_grid = {\n",
    "    \"clf__C\": [0.15, 0.2, 0.25],  # Inverse of regularization strength\n",
    "    \"clf__penalty\": [\"l2\"],  # Regularization type\n",
    "    \"clf__solver\": [\n",
    "        \"saga\",\n",
    "    ],  # Solvers that support l1/l2\n",
    "    \"clf__class_weight\": [None],  # Handle class imbalance\n",
    "}\n",
    "\n",
    "scoring = {\"f1_macro\": \"f1_macro\", \"accuracy\": \"accuracy\"}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    pipe,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=40,  # Number of random trials\n",
    "    scoring=scoring,\n",
    "    refit=\"f1_macro\",  # Optimize for F1-macro\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    return_train_score=True,\n",
    ")\n",
    "\n",
    "# Fit on training data\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters\n",
    "print(\"Best Logistic Regression Params:\", random_search.best_params_)\n",
    "best_params = random_search.best_params_\n",
    "best_index = random_search.best_index_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1f03f5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Train Accuracy (mean): 0.8591\n",
      "CV Test Accuracy (mean): 0.7000\n",
      "CV Train F1 (mean): 0.8551\n",
      "CV Test F1 (mean): 0.6914\n",
      "CV Fit Time (mean, s): 2.8393\n",
      "Holdout Accuracy: 0.7200\n",
      "Holdout F1 Score (macro): 0.7308\n",
      "Holdout Prediction Time (s): 0.0013\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    ")\n",
    "import time\n",
    "\n",
    "\n",
    "best_params = random_search.best_params_\n",
    "best_index = random_search.best_index_\n",
    "# CV summary from GridSearchCV\n",
    "best_train_acc = random_search.cv_results_[\"mean_train_accuracy\"][best_index]\n",
    "best_test_acc = random_search.cv_results_[\"mean_test_accuracy\"][best_index]\n",
    "best_train_f1 = random_search.cv_results_[\"mean_train_f1_macro\"][best_index]\n",
    "best_test_f1 = random_search.cv_results_[\"mean_test_f1_macro\"][best_index]\n",
    "fit_time = random_search.cv_results_[\"mean_fit_time\"][best_index]\n",
    "\n",
    "print(f\"CV Train Accuracy (mean): {best_train_acc:.4f}\")\n",
    "print(f\"CV Test Accuracy (mean): {best_test_acc:.4f}\")\n",
    "print(f\"CV Train F1 (mean): {best_train_f1:.4f}\")\n",
    "print(f\"CV Test F1 (mean): {best_test_f1:.4f}\")\n",
    "print(f\"CV Fit Time (mean, s): {fit_time:.4f}\")\n",
    "\n",
    "# Use the best estimator from GridSearchCV\n",
    "best_model = random_search.best_estimator_\n",
    "\n",
    "# Evaluate on hold-out test set\n",
    "start = time.time()\n",
    "y_pred_test = best_model.predict(X_test)\n",
    "test_time = time.time() - start\n",
    "\n",
    "# Compute metrics\n",
    "test_acc = accuracy_score(y_test, y_pred_test)\n",
    "test_f1 = f1_score(y_test, y_pred_test, average=\"macro\")\n",
    "\n",
    "# Print results\n",
    "print(f\"Holdout Accuracy: {test_acc:.4f}\")\n",
    "print(f\"Holdout F1 Score (macro): {test_f1:.4f}\")\n",
    "print(f\"Holdout Prediction Time (s): {test_time:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "97f673da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Best MLP Params: {'clf__solver': 'adam', 'clf__max_iter': 160, 'clf__learning_rate': 'constant', 'clf__hidden_layer_sizes': (128,), 'clf__alpha': 2.3, 'clf__activation': 'relu'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, StratifiedKFold\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipe = Pipeline([(\"scaler\", StandardScaler()), (\"clf\", MLPClassifier(random_state=0))])\n",
    "# Hyperparameter grid\n",
    "param_grid = {\n",
    "    \"clf__hidden_layer_sizes\": [\n",
    "        (128,),\n",
    "    ],  # slightly smaller or 2-layer networks\n",
    "    \"clf__activation\": [\"relu\"],  # test smoother gradients with tanh\n",
    "    \"clf__solver\": [\"adam\"],  # keep adam\n",
    "    \"clf__alpha\": [2.3],  # slightly stronger regularization to reduce overfit\n",
    "    \"clf__learning_rate\": [\"constant\"],  # adaptive might improve test performance\n",
    "    \"clf__max_iter\": [160],  # allow more iterations to ensure convergence\n",
    "}\n",
    "scoring = {\"f1_macro\": \"f1_macro\", \"accuracy\": \"accuracy\"}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "random_search = RandomizedSearchCV(\n",
    "    pipe,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=30,  # number of random trials\n",
    "    scoring=scoring,\n",
    "    refit=\"f1_macro\",\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    return_train_score=True,\n",
    ")\n",
    "\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best MLP Params:\", random_search.best_params_)\n",
    "best_params = random_search.best_params_\n",
    "\n",
    "best_index = random_search.best_index_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb68bb8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Train Accuracy (mean): 0.8906\n",
      "CV Test Accuracy (mean): 0.7213\n",
      "CV Train F1 (mean): 0.8881\n",
      "CV Test F1 (mean): 0.7093\n",
      "CV Fit Time (mean, s): 1.1256\n",
      "Holdout Accuracy: 0.7400\n",
      "Holdout F1 Score (macro): 0.7525\n",
      "Holdout Prediction Time (s): 0.0019\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    ")\n",
    "import time\n",
    "\n",
    "\n",
    "best_params = random_search.best_params_\n",
    "best_index = random_search.best_index_\n",
    "# CV summary from GridSearchCV\n",
    "best_train_acc = random_search.cv_results_[\"mean_train_accuracy\"][best_index]\n",
    "best_test_acc = random_search.cv_results_[\"mean_test_accuracy\"][best_index]\n",
    "best_train_f1 = random_search.cv_results_[\"mean_train_f1_macro\"][best_index]\n",
    "best_test_f1 = random_search.cv_results_[\"mean_test_f1_macro\"][best_index]\n",
    "fit_time = random_search.cv_results_[\"mean_fit_time\"][best_index]\n",
    "\n",
    "print(f\"CV Train Accuracy (mean): {best_train_acc:.4f}\")\n",
    "print(f\"CV Test Accuracy (mean): {best_test_acc:.4f}\")\n",
    "print(f\"CV Train F1 (mean): {best_train_f1:.4f}\")\n",
    "print(f\"CV Test F1 (mean): {best_test_f1:.4f}\")\n",
    "print(f\"CV Fit Time (mean, s): {fit_time:.4f}\")\n",
    "\n",
    "# Use the best estimator from GridSearchCV\n",
    "best_model = random_search.best_estimator_\n",
    "\n",
    "# Evaluate on hold-out test set\n",
    "start = time.time()\n",
    "y_pred_test = best_model.predict(X_test)\n",
    "test_time = time.time() - start\n",
    "\n",
    "# Compute metrics\n",
    "test_acc = accuracy_score(y_test, y_pred_test)\n",
    "test_f1 = f1_score(y_test, y_pred_test, average=\"macro\")\n",
    "\n",
    "# Print results\n",
    "print(f\"Holdout Accuracy: {test_acc:.4f}\")\n",
    "print(f\"Holdout F1 Score (macro): {test_f1:.4f}\")\n",
    "print(f\"Holdout Prediction Time (s): {test_time:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5bcf7282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "Best KNN Params: {'clf__weights': 'uniform', 'clf__p': 1, 'clf__n_neighbors': 13, 'clf__metric': 'manhattan'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# KNN pipeline\n",
    "pipe = Pipeline([(\"scaler\", StandardScaler()), (\"clf\", KNeighborsClassifier())])\n",
    "\n",
    "# Hyperparameter grid\n",
    "param_grid = {\n",
    "    \"clf__n_neighbors\": [11, 13, 15],  # explore smaller to moderate k\n",
    "    \"clf__weights\": [\"uniform\"],  # uniform or weighted by distance\n",
    "    \"clf__metric\": [\"manhattan\"],  # distance metrics\n",
    "    \"clf__p\": [1, 2],  # L1 or L2 for Minkowski\n",
    "}\n",
    "\n",
    "# Scoring metrics\n",
    "scoring = {\"f1_macro\": \"f1_macro\", \"accuracy\": \"accuracy\"}\n",
    "\n",
    "# Stratified K-Fold CV\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "# Randomized Search\n",
    "random_search = RandomizedSearchCV(\n",
    "    pipe,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=50,  # number of random trials\n",
    "    scoring=scoring,\n",
    "    refit=\"f1_macro\",  # refit best model by macro F1\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    return_train_score=True,\n",
    ")\n",
    "\n",
    "# Fit on training data\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters\n",
    "print(\"Best KNN Params:\", random_search.best_params_)\n",
    "best_params = random_search.best_params_\n",
    "best_index = random_search.best_index_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c68ab8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Train Accuracy (mean): 0.7169\n",
      "CV Test Accuracy (mean): 0.6487\n",
      "CV Train F1 (mean): 0.7123\n",
      "CV Test F1 (mean): 0.6430\n",
      "CV Fit Time (mean, s): 0.0040\n",
      "Holdout Accuracy: 0.6650\n",
      "Holdout F1 Score (macro): 0.6656\n",
      "Holdout Prediction Time (s): 0.0284\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    ")\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "best_params = random_search.best_params_\n",
    "best_index = random_search.best_index_\n",
    "# CV summary from GridSearchCV\n",
    "best_train_acc = random_search.cv_results_[\"mean_train_accuracy\"][best_index]\n",
    "best_test_acc = random_search.cv_results_[\"mean_test_accuracy\"][best_index]\n",
    "best_train_f1 = random_search.cv_results_[\"mean_train_f1_macro\"][best_index]\n",
    "best_test_f1 = random_search.cv_results_[\"mean_test_f1_macro\"][best_index]\n",
    "fit_time = random_search.cv_results_[\"mean_fit_time\"][best_index]\n",
    "\n",
    "print(f\"CV Train Accuracy (mean): {best_train_acc:.4f}\")\n",
    "print(f\"CV Test Accuracy (mean): {best_test_acc:.4f}\")\n",
    "print(f\"CV Train F1 (mean): {best_train_f1:.4f}\")\n",
    "print(f\"CV Test F1 (mean): {best_test_f1:.4f}\")\n",
    "print(f\"CV Fit Time (mean, s): {fit_time:.4f}\")\n",
    "\n",
    "# Use the best estimator from GridSearchCV\n",
    "best_model = random_search.best_estimator_\n",
    "\n",
    "# Evaluate on hold-out test set\n",
    "start = time.time()\n",
    "y_pred_test = best_model.predict(X_test)\n",
    "test_time = time.time() - start\n",
    "\n",
    "# Compute metrics\n",
    "test_acc = accuracy_score(y_test, y_pred_test)\n",
    "test_f1 = f1_score(y_test, y_pred_test, average=\"macro\")\n",
    "\n",
    "# Print results\n",
    "print(f\"Holdout Accuracy: {test_acc:.4f}\")\n",
    "print(f\"Holdout F1 Score (macro): {test_f1:.4f}\")\n",
    "print(f\"Holdout Prediction Time (s): {test_time:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e97c377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error correlation MLP-LR: 0.7727995396408661\n",
      "Error correlation MLP-KNN: 0.4970265802013242\n",
      "Error correlation LR-KNN: 0.4303445905856845\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import time\n",
    "\n",
    "# === Base models with scaling ===\n",
    "lr_pipe = Pipeline(\n",
    "    [\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\n",
    "            \"clf\",\n",
    "            LogisticRegression(\n",
    "                solver=\"saga\", penalty=\"l2\", C=0.2, max_iter=500, random_state=0\n",
    "            ),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "mlp_pipe = Pipeline(\n",
    "    [\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\n",
    "            \"clf\",\n",
    "            MLPClassifier(\n",
    "                hidden_layer_sizes=(128,),\n",
    "                solver=\"adam\",\n",
    "                learning_rate=\"constant\",\n",
    "                alpha=2.3,\n",
    "                max_iter=160,\n",
    "                random_state=0,\n",
    "            ),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "knn_pipe = Pipeline(\n",
    "    [\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\n",
    "            \"clf\",\n",
    "            KNeighborsClassifier(\n",
    "                n_neighbors=13, weights=\"uniform\", metric=\"manhattan\", p=1\n",
    "            ),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "y_true = y_test\n",
    "\n",
    "lr_pipe.fit(X_train, y_train)\n",
    "mlp_pipe.fit(X_train, y_train)\n",
    "knn_pipe.fit(X_train, y_train)\n",
    "\n",
    "y_pred_mlp = mlp_pipe.predict(X_test)\n",
    "y_pred_lr = lr_pipe.predict(X_test)\n",
    "y_pred_knn = knn_pipe.predict(X_test)\n",
    "\n",
    "errors_mlp = (y_true != y_pred_mlp).astype(int)\n",
    "errors_lr = (y_true != y_pred_lr).astype(int)\n",
    "errors_knn = (y_true != y_pred_knn).astype(int)\n",
    "\n",
    "corr_mlp_lr = np.corrcoef(errors_mlp, errors_lr)[0, 1]\n",
    "corr_mlp_knn = np.corrcoef(errors_mlp, errors_knn)[0, 1]\n",
    "corr_lr_knn = np.corrcoef(errors_lr, errors_knn)[0, 1]\n",
    "\n",
    "print(\"Error correlation MLP-LR:\", corr_mlp_lr)\n",
    "print(\"Error correlation MLP-KNN:\", corr_mlp_knn)\n",
    "print(\"Error correlation LR-KNN:\", corr_lr_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d833b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Train Accuracy (mean): 0.8850\n",
      "CV Test Accuracy (mean): 0.7350\n",
      "CV Train F1 (mean): 0.8827\n",
      "CV Test F1 (mean): 0.7260\n",
      "CV Fit Time (mean, s): 0.9848\n",
      "Holdout Accuracy: 0.7350\n",
      "Holdout F1 Score (macro): 0.7461\n",
      "Holdout Prediction Time (s): 0.0176\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.80      0.73        15\n",
      "           1       0.61      1.00      0.76        11\n",
      "           2       0.56      0.67      0.61        27\n",
      "           3       0.52      0.77      0.62        22\n",
      "           4       0.75      0.52      0.62        23\n",
      "           5       0.90      0.50      0.64        18\n",
      "           6       0.89      0.80      0.84        20\n",
      "           7       0.90      0.75      0.82        24\n",
      "           8       0.38      0.40      0.39        15\n",
      "           9       0.74      0.56      0.64        25\n",
      "\n",
      "    accuracy                           0.67       200\n",
      "   macro avg       0.69      0.68      0.67       200\n",
      "weighted avg       0.70      0.67      0.67       200\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[12  0  1  0  0  0  0  0  1  1]\n",
      " [ 0 11  0  0  0  0  0  0  0  0]\n",
      " [ 2  2 18  3  0  1  0  0  0  1]\n",
      " [ 0  0  2 17  0  0  1  0  1  1]\n",
      " [ 1  0  1  3 12  0  1  0  5  0]\n",
      " [ 0  4  2  2  0  9  0  0  1  0]\n",
      " [ 1  0  2  1  0  0 16  0  0  0]\n",
      " [ 0  0  0  1  1  0  0 18  2  2]\n",
      " [ 1  0  1  2  3  0  0  2  6  0]\n",
      " [ 1  1  5  4  0  0  0  0  0 14]]\n"
     ]
    }
   ],
   "source": [
    "# === Voting ensemble ===\n",
    "ensemble = VotingClassifier(\n",
    "    estimators=[(\"knn\", knn_pipe), (\"mlp\", mlp_pipe)],\n",
    "    voting=\"soft\",  # uses predicted probabilities\n",
    "    weights=[1, 3],\n",
    ")\n",
    "\n",
    "# === Cross-validation metrics ===\n",
    "scoring = {\"accuracy\": \"accuracy\", \"f1_macro\": \"f1_macro\"}\n",
    "cv_results = cross_validate(\n",
    "    ensemble,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    cv=5,\n",
    "    scoring=scoring,\n",
    "    return_train_score=True,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "print(f\"CV Train Accuracy (mean): {cv_results['train_accuracy'].mean():.4f}\")\n",
    "print(f\"CV Test Accuracy (mean): {cv_results['test_accuracy'].mean():.4f}\")\n",
    "print(f\"CV Train F1 (mean): {cv_results['train_f1_macro'].mean():.4f}\")\n",
    "print(f\"CV Test F1 (mean): {cv_results['test_f1_macro'].mean():.4f}\")\n",
    "\n",
    "# === Fit and holdout evaluation ===\n",
    "start_fit = time.time()\n",
    "ensemble.fit(X_train, y_train)\n",
    "fit_time = time.time() - start_fit\n",
    "\n",
    "start_pred = time.time()\n",
    "y_pred = ensemble.predict(X_test)\n",
    "pred_time = time.time() - start_pred\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1_macro = f1_score(y_test, y_pred, average=\"macro\")\n",
    "\n",
    "print(f\"CV Fit Time (mean, s): {cv_results['fit_time'].mean():.4f}\")\n",
    "print(f\"Holdout Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Holdout F1 Score (macro): {f1_macro:.4f}\")\n",
    "print(f\"Holdout Prediction Time (s): {pred_time:.4f}\")\n",
    "# Detailed evaluation\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_test))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "70c6c8bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Train Accuracy (mean): 0.8850\n",
      "CV Test Accuracy (mean): 0.7350\n",
      "CV Train F1 (mean): 0.8827\n",
      "CV Test F1 (mean): 0.7260\n",
      "CV Fit Time (mean, s): 1.0526\n",
      "Holdout Accuracy: 0.7400\n",
      "Holdout F1 Score (macro): 0.7525\n",
      "Holdout Prediction Time (s): 0.0013\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.80      0.73        15\n",
      "           1       0.61      1.00      0.76        11\n",
      "           2       0.56      0.67      0.61        27\n",
      "           3       0.52      0.77      0.62        22\n",
      "           4       0.75      0.52      0.62        23\n",
      "           5       0.90      0.50      0.64        18\n",
      "           6       0.89      0.80      0.84        20\n",
      "           7       0.90      0.75      0.82        24\n",
      "           8       0.38      0.40      0.39        15\n",
      "           9       0.74      0.56      0.64        25\n",
      "\n",
      "    accuracy                           0.67       200\n",
      "   macro avg       0.69      0.68      0.67       200\n",
      "weighted avg       0.70      0.67      0.67       200\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[12  0  1  0  0  0  0  0  1  1]\n",
      " [ 0 11  0  0  0  0  0  0  0  0]\n",
      " [ 2  2 18  3  0  1  0  0  0  1]\n",
      " [ 0  0  2 17  0  0  1  0  1  1]\n",
      " [ 1  0  1  3 12  0  1  0  5  0]\n",
      " [ 0  4  2  2  0  9  0  0  1  0]\n",
      " [ 1  0  2  1  0  0 16  0  0  0]\n",
      " [ 0  0  0  1  1  0  0 18  2  2]\n",
      " [ 1  0  1  2  3  0  0  2  6  0]\n",
      " [ 1  1  5  4  0  0  0  0  0 14]]\n"
     ]
    }
   ],
   "source": [
    "# Final chosen model - MLP\n",
    "\n",
    "scoring = {\"accuracy\": \"accuracy\", \"f1_macro\": \"f1_macro\"}\n",
    "cv_results = cross_validate(\n",
    "    ensemble,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    cv=5,\n",
    "    scoring=scoring,\n",
    "    return_train_score=True,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "print(f\"CV Train Accuracy (mean): {cv_results['train_accuracy'].mean():.4f}\")\n",
    "print(f\"CV Test Accuracy (mean): {cv_results['test_accuracy'].mean():.4f}\")\n",
    "print(f\"CV Train F1 (mean): {cv_results['train_f1_macro'].mean():.4f}\")\n",
    "print(f\"CV Test F1 (mean): {cv_results['test_f1_macro'].mean():.4f}\")\n",
    "\n",
    "# === Fit and holdout evaluation ===\n",
    "start_fit = time.time()\n",
    "mlp_pipe.fit(X_train, y_train)\n",
    "fit_time = time.time() - start_fit\n",
    "\n",
    "start_pred = time.time()\n",
    "y_pred = mlp_pipe.predict(X_test)\n",
    "pred_time = time.time() - start_pred\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1_macro = f1_score(y_test, y_pred, average=\"macro\")\n",
    "\n",
    "print(f\"CV Fit Time (mean, s): {cv_results['fit_time'].mean():.4f}\")\n",
    "print(f\"Holdout Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Holdout F1 Score (macro): {f1_macro:.4f}\")\n",
    "print(f\"Holdout Prediction Time (s): {pred_time:.4f}\")\n",
    "# Detailed evaluation\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_test))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a2d0b3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(mlp_pipe, open(\"model.pkl\", \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
